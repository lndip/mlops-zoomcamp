{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce28a07d-9bd6-4bbe-8f28-57ea54b8e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98d7eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 19:47:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/13 19:47:14 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2025/12/13 19:47:14 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/13 19:47:15 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/13 19:47:15 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/mlops-zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1765655235573, experiment_id='1', last_update_time=1765655235573, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c68e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d922a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('./data/green_tripdata_2025-01.parquet')\n",
    "df_val = read_dataframe('./data/green_tripdata_2025-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd23d610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46307, 44218)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8643e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26cd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da096e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb21f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.09887666573155"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67b0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c98b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "\n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2eb0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/pipenv-sAJolYUV/lib/python3.11/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25523e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbd639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run(run_name=\"xgboost\"):\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        mlflow.xgboost.log_model(booster, name=\"xgboost\")\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c5b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/pipenv-sAJolYUV/lib/python3.11/site-packages/xgboost/callback.py:386: UserWarning: [19:48:43] WARNING: /workspace/src/objective/regression_obj.cu:282: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:5.61555                          \n",
      "[1]\tvalidation-rmse:5.42694                          \n",
      "[2]\tvalidation-rmse:5.40820                          \n",
      "[3]\tvalidation-rmse:5.40812                          \n",
      "[4]\tvalidation-rmse:5.40509                          \n",
      "[5]\tvalidation-rmse:5.40115                          \n",
      "[6]\tvalidation-rmse:5.40182                          \n",
      "[7]\tvalidation-rmse:5.40183                          \n",
      "[8]\tvalidation-rmse:5.39671                          \n",
      "[9]\tvalidation-rmse:5.39766                          \n",
      "[10]\tvalidation-rmse:5.39741                         \n",
      "[11]\tvalidation-rmse:5.40101                         \n",
      "[12]\tvalidation-rmse:5.40163                         \n",
      "[13]\tvalidation-rmse:5.40128                         \n",
      "[14]\tvalidation-rmse:5.40730                         \n",
      "[15]\tvalidation-rmse:5.40586                         \n",
      "[16]\tvalidation-rmse:5.40588                         \n",
      "[17]\tvalidation-rmse:5.40594                         \n",
      "[18]\tvalidation-rmse:5.40679                         \n",
      "[19]\tvalidation-rmse:5.40782                         \n",
      "[20]\tvalidation-rmse:5.40873                         \n",
      "[21]\tvalidation-rmse:5.40603                         \n",
      "[22]\tvalidation-rmse:5.41022                         \n",
      "[23]\tvalidation-rmse:5.41102                         \n",
      "[24]\tvalidation-rmse:5.41229                         \n",
      "[25]\tvalidation-rmse:5.41273                         \n",
      "[26]\tvalidation-rmse:5.41475                         \n",
      "[27]\tvalidation-rmse:5.41269                         \n",
      "[28]\tvalidation-rmse:5.41193                         \n",
      "[29]\tvalidation-rmse:5.41536                         \n",
      "[30]\tvalidation-rmse:5.41268                         \n",
      "[31]\tvalidation-rmse:5.41120                         \n",
      "[32]\tvalidation-rmse:5.41270                         \n",
      "[33]\tvalidation-rmse:5.41471                         \n",
      "[34]\tvalidation-rmse:5.41370                         \n",
      "[35]\tvalidation-rmse:5.41472                         \n",
      "[36]\tvalidation-rmse:5.41525                         \n",
      "[37]\tvalidation-rmse:5.41532                         \n",
      "[38]\tvalidation-rmse:5.41179                         \n",
      "[39]\tvalidation-rmse:5.41163                         \n",
      "[40]\tvalidation-rmse:5.41025                         \n",
      "[41]\tvalidation-rmse:5.41175                         \n",
      "[42]\tvalidation-rmse:5.41230                         \n",
      "[43]\tvalidation-rmse:5.41323                         \n",
      "[44]\tvalidation-rmse:5.41490                         \n",
      "[45]\tvalidation-rmse:5.41416                         \n",
      "[46]\tvalidation-rmse:5.41580                         \n",
      "[47]\tvalidation-rmse:5.41501                         \n",
      "[48]\tvalidation-rmse:5.41627                         \n",
      "[49]\tvalidation-rmse:5.41742                         \n",
      "[50]\tvalidation-rmse:5.41724                         \n",
      "[51]\tvalidation-rmse:5.41934                         \n",
      "[52]\tvalidation-rmse:5.41872                         \n",
      "[53]\tvalidation-rmse:5.42034                         \n",
      "[54]\tvalidation-rmse:5.41996                         \n",
      "[55]\tvalidation-rmse:5.42139                         \n",
      "[56]\tvalidation-rmse:5.42143                         \n",
      "[57]\tvalidation-rmse:5.42070                         \n",
      "[58]\tvalidation-rmse:5.42515                         \n",
      "100%|██████████| 1/1 [00:21<00:00, 21.19s/trial, best loss: 5.425153464727356]\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e32c950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/pipenv-sAJolYUV/lib/python3.11/site-packages/sklearn/svm/_base.py:1258: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "for model_class, model_name in zip([RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, LinearSVR], [\"RandomForest\", \"GradientBoosting\", \"ExtraTrees\", \"LinearSVR\"]):\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2025-01.csv\")\n",
    "        mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2025-02.csv\")\n",
    "        \n",
    "        with open(\"models/preprocessor.b\", \"wb\") as f:\n",
    "            pickle.dump(dv, f)\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        mlmodel = model_class()\n",
    "        mlmodel.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = mlmodel.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        mlflow.sklearn.log_model(mlmodel, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa856f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipenv-sAJolYUV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
